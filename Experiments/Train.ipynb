{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure plotting\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['figure.figsize'] = (16, 10)\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['font.size'] = 25\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import config\n",
    "import Data\n",
    "\n",
    "import ScoreFunctions\n",
    "import Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize experiment\n",
    "- Train dataset size changes from start_n to end_n  \n",
    "- Info about the experiment is saved at ./Results/name  \n",
    "- draw_* options could be True only if ndim <= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = config.ExperimentInfo(\n",
    "    ndim_    = 3, \n",
    "    total_n_ = 1000, \n",
    "    start_n_ = 50, \n",
    "    end_n_   = 500, \n",
    "    test_n_  = 500, \n",
    "    name_    = \"SkinTime2\",\n",
    "    dataset_     = Data.Skin,\n",
    "    draw_data_   = False,\n",
    "    draw_scores_ = False,\n",
    "    update_freq_ = 10,\n",
    "    comparsion_  = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 74,  85, 123],\n",
       "       [ 73,  84, 122],\n",
       "       [ 72,  83, 121],\n",
       "       ...,\n",
       "       [163, 162, 112],\n",
       "       [163, 162, 112],\n",
       "       [255, 255, 255]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.dataset.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some needed variables. We aren't interested in them since we look into active learning part, not model charachteristics. Still the variables are needed to make it all work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 100\n",
    "lengthscale = 1\n",
    "\n",
    "k = GPy.kern.RBF(info.ndim, variance = var, lengthscale = lengthscale)\n",
    "lik = GPy.likelihoods.Bernoulli()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example Inference\n",
    "To see whether gaussian process learns on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1mrbf.       \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |  142.53276680389752  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  116.48880124747016  |      +ve      |        \n",
      "0.952\n"
     ]
    }
   ],
   "source": [
    "m = GPy.core.GP(\n",
    "    X      = info.dataset.X_train,\n",
    "    Y      = info.dataset.y_train.reshape(-1, 1), \n",
    "    kernel = k, \n",
    "    inference_method = GPy.inference.latent_function_inference.expectation_propagation.EP(),\n",
    "    likelihood = lik)\n",
    "\n",
    "m.optimize()\n",
    "print(m.kern)\n",
    "\n",
    "if (info.draw_data):\n",
    "    m.plot(plot_density = True)\n",
    "    \n",
    "prediction = m.predict(info.dataset.X_test.reshape(-1, info.ndim))[:][0]\n",
    "print(accuracy_score(info.dataset.y_test, Utils.to_labels(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only needed if we want to compare active learning with traditional approaches\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "acc_lr = []\n",
    "acc_kn = []\n",
    "acc_dt = []\n",
    "acc_rf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main loop\n",
    "Train 6 gps with different score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mvar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2abd0168a224689ade0b25e9ab70fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=450), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/daria.kotova/anaconda2/lib/python2.7/site-packages/paramz/transformations.py:111: RuntimeWarning:overflow encountered in expm1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "34.3799080849\n",
      "0.565038919449\n",
      "Hvar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8beab053d104f6f868bd0c1e8342672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=450), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "37.5859041214\n",
      "1.06514453888\n",
      "RKHS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da13a581d544c0d9c1cf91bd05d7968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=450), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "38.0880661011\n",
      "1.16137552261\n",
      "rand\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e28acc3bf04778bc2244cb7d4bf96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=450), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "37.4343550205\n",
      "0.0121328830719\n",
      "l2fm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a37454ac98426a92fb64e899d19cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=450), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "39.0847480297\n",
      "2.16635560989\n",
      "sqsm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a2300fde5e40b79dd92d4b7e847c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=450), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4b85b28ab994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# 1. calculate score at each point of the rest dataset in U and y_u, get the index of maximum score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mstart1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mend1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/ActiveLearning-with-GP/Experiments/ScoreFunctions.py\u001b[0m in \u001b[0;36mcalculate_scores_sqsm\u001b[0;34m(U, m, X_train, y_train, inv_K)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0minference_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_function_inference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 likelihood = lik)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/paramz/parameterized.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_initialized_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/paramz/core/parameter_core.pyc\u001b[0m in \u001b[0;36minitialize_parameter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_highest_parent_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#logger.debug(\"calling parameters changed\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_highest_parent_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect_fixes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/paramz/core/updateable.pyc\u001b[0m in \u001b[0;36mtrigger_update\u001b[0;34m(self, trigger_parent)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m#print \"Warning: updates are off, updating the model will do nothing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trigger_params_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigger_parent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/paramz/core/parameter_core.pyc\u001b[0m in \u001b[0;36m_trigger_params_changed\u001b[0;34m(self, trigger_parent)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \"\"\"\n\u001b[1;32m    133\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trigger_params_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigger_parent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fixed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrigger_parent\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_size_transformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/paramz/core/observable.pyc\u001b[0m in \u001b[0;36mnotify_observers\u001b[0;34m(self, which, min_priority)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mwhich\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_priority\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mcallble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/paramz/core/parameter_core.pyc\u001b[0m in \u001b[0;36m_parameters_changed_notification\u001b[0;34m(self, me, which)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \"\"\"\n\u001b[1;32m    507\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_copy_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m \u001b[0;31m# tells the optimizer array to update on next request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pass_through_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/GPy/core/gp.pyc\u001b[0m in \u001b[0;36mparameters_changed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0myourself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0munexpected\u001b[0m \u001b[0mconsequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_marginal_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dL_dthetaL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_gradients_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dL_dK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/GPy/inference/latent_function_inference/expectation_propagation.pyc\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, kern, X, likelihood, Y, mean_function, Y_metadata, precision, K)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_ep_approximation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;31m#if we don't yet have the results of runnign EP, run EP and store the computed factors in self._ep_approximation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga_approx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcav_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_Z_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ep_approximation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpectation_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;31m#if we've already run EP, just use the existing approximation stored in self._ep_approximation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/GPy/inference/latent_function_inference/expectation_propagation.pyc\u001b[0m in \u001b[0;36mexpectation_propagation\u001b[0;34m(self, mean_prior, K, Y, likelihood, Y_metadata)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcav_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarg_moments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga_approx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m#(re) compute Sigma and mu using full Cholesky decompy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/GPy/inference/latent_function_inference/expectation_propagation.pyc\u001b[0m in \u001b[0;36m_local_updates\u001b[0;34m(self, num_data, cav_params, post_params, marg_moments, ga_approx, likelihood, Y, Y_metadata, update_order)\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mY_metadata_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m#Marginal moments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mmarg_moments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarg_moments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarg_moments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma2_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoments_match_ep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcav_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcav_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_metadata_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_metadata_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;31m#Site parameters update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/GPy/likelihoods/bernoulli.pyc\u001b[0m in \u001b[0;36mmoments_match_ep\u001b[0;34m(self, Y_i, tau_i, v_i, Y_metadata_i)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp_link\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProbit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msign\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv_i\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_i\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtau_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mphi_div_Phi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderivLogCdfNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mlog_Z_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogCdfNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/GPy/util/univariate_Gaussian.pyc\u001b[0m in \u001b[0;36mderivLogCdfNormal\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0m_erfRationalHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogPdfNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_erfRationalHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daria.kotova/anaconda2/lib/python2.7/site-packages/GPy/util/univariate_Gaussian.pyc\u001b[0m in \u001b[0;36mlogPdfNormal\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     31\u001b[0m      \u001b[0;32min\u001b[0m \u001b[0mC\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMatthias\u001b[0m \u001b[0mSeeger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mM_LN2PI\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcdfNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "X_train_0   = info.dataset.X_train\n",
    "y_train_0   = info.dataset.y_train\n",
    "U_0         = info.dataset.U\n",
    "y_U_0       = info.dataset.y_U\n",
    "\n",
    "score_functions = [\n",
    "    ScoreFunctions.calculate_scores_mvar,\n",
    "    ScoreFunctions.calculate_scores_Hvar, \n",
    "    ScoreFunctions.calculate_scores_RKHS,\n",
    "    ScoreFunctions.calculate_scores_rand, \n",
    "    ScoreFunctions.calculate_scores_l2fm,\n",
    "    ScoreFunctions.calculate_scores_sqsm]\n",
    "\n",
    "import time\n",
    "\n",
    "for score in score_functions:\n",
    "    info.dataset.X_train = X_train_0\n",
    "    info.dataset.y_train = y_train_0\n",
    "    info.dataset.U = U_0\n",
    "    info.dataset.y_U = y_U_0\n",
    "    \n",
    "    k = GPy.kern.RBF(info.ndim, variance = var, lengthscale = lengthscale)\n",
    "    m = GPy.core.GP(\n",
    "        X      = info.dataset.X_train,\n",
    "        Y      = info.dataset.y_train.reshape(-1, 1), \n",
    "        kernel = k, \n",
    "        inference_method = GPy.inference.latent_function_inference.expectation_propagation.EP(),\n",
    "        likelihood = lik)\n",
    "    \n",
    "    K     = Utils.get_K(m, info.dataset.X_train)\n",
    "    inv_K = Utils.get_inv_K(m, info.dataset.X_train) \n",
    "    \n",
    "    score_name = str(score)[27:31]\n",
    "    print(score_name)\n",
    "    \n",
    "    start = time.time()\n",
    "    score_time = 0\n",
    "    \n",
    "    for i in tqdm(range(info.start_n, info.end_n)):\n",
    "        # 0. learn GP on the data with update_frequency\n",
    "        if i % info.update_freq == 0:\n",
    "            m = GPy.core.GP(\n",
    "                X      = info.dataset.X_train,\n",
    "                Y      = info.dataset.y_train.reshape(-1, 1), \n",
    "                kernel = m.kern, \n",
    "                inference_method = GPy.inference.latent_function_inference.expectation_propagation.EP(),\n",
    "                likelihood = lik)\n",
    "\n",
    "            m.optimize(messages = False)\n",
    "        \n",
    "        # 1. calculate score at each point of the rest dataset in U and y_u, get the index of maximum score\n",
    "        start1 = time.time()\n",
    "        scores = score(np.array(info.dataset.U), m, info.dataset.X_train, info.dataset.y_train, inv_K)\n",
    "        end1 = time.time()\n",
    "        \n",
    "        score_time += end1 - start1\n",
    "        ind = np.argmax(scores)\n",
    "        \n",
    "        # 2. append new point to the training dataset and update inv_K\n",
    "        info.dataset.X_train = np.concatenate(\n",
    "            (info.dataset.X_train, \n",
    "             info.dataset.U[ind].reshape(-1, info.ndim)), \n",
    "            axis = 0)\n",
    "        info.dataset.y_train = np.append(info.dataset.y_train, info.dataset.y_U[ind]).reshape(-1, 1)\n",
    "        \n",
    "        a = m.kern.K(\n",
    "            info.dataset.U[ind].reshape(-1, info.ndim), \n",
    "            info.dataset.X_train[:info.dataset.X_train.shape[0]-1]).T\n",
    "        \n",
    "        inv_K = Utils.update_inv_K(m, info.dataset.X_train, inv_K, info.dataset.U[ind], a)\n",
    "        \n",
    "        # 2.5. draw score if needed\n",
    "        # placing this function call right here is important\n",
    "        # since draw_score should see whole U included the point to be deleted\n",
    "        if info.draw_scores:\n",
    "            info.dataset.draw_score(scores, score_name, info.name, i, m, score, inv_K)\n",
    "\n",
    "        # 3. delete new point from U since it is labeled now\n",
    "        info.dataset.U = np.delete(info.dataset.U, ind, axis = 0)\n",
    "        info.dataset.y_U = np.delete(info.dataset.y_U, ind)\n",
    "\n",
    "        # 4. count accuracy\n",
    "        prediction = m.predict(info.dataset.X_test.reshape(-1, info.ndim))[:][0]\n",
    "        cur_accuracy = accuracy_score(info.dataset.y_test, Utils.to_labels(prediction))\n",
    "        \n",
    "        info.per_score_acc[score_name].append(cur_accuracy)\n",
    "        info.save(score_name)\n",
    "        \n",
    "        del a    \n",
    "        del scores\n",
    "        del prediction\n",
    "        \n",
    "        # 5. compare with other models\n",
    "        # it is important to learn traditional methods on train dataset of rand score function\n",
    "        if info.comparsion and score == ScoreFunctions.calculate_scores_rand:\n",
    "            lr = LogisticRegression(solver = 'lbfgs').fit(info.dataset.X_train, info.dataset.y_train)\n",
    "            acc_lr.append(lr.score(info.dataset.X_test, info.dataset.y_test))\n",
    "\n",
    "            kn = KNeighborsClassifier().fit(info.dataset.X_train, info.dataset.y_train)\n",
    "            acc_kn.append(kn.score(info.dataset.X_test, info.dataset.y_test))\n",
    "\n",
    "            dt = DecisionTreeClassifier().fit(info.dataset.X_train, info.dataset.y_train)\n",
    "            acc_dt.append(dt.score(info.dataset.X_test, info.dataset.y_test))\n",
    "\n",
    "            rf = RandomForestClassifier().fit(info.dataset.X_train, info.dataset.y_train)\n",
    "            acc_rf.append(rf.score(info.dataset.X_test, info.dataset.y_test))\n",
    "\n",
    "            del lr\n",
    "            del kn\n",
    "            del dt\n",
    "            del rf\n",
    "        \n",
    "    end = time.time()\n",
    "    info.times[score_name] = score_time\n",
    "    print(end - start)\n",
    "    print(score_time)\n",
    "    #after the gp is learned save it to models\n",
    "    models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(\"./Results/\" + info.name + \"/description.txt\", 'a')\n",
    "        \n",
    "out.write(\n",
    "      \"time rand = \" + str(info.times[\"rand\"]) + \"\\n\"\n",
    "    + \"time mvar = \" + str(info.times[\"mvar\"]) + \"\\n\"\n",
    "    + \"time RKHS = \" + str(info.times[\"RKHS\"]) + \"\\n\"\n",
    "    + \"time Hvar = \" + str(info.times[\"Hvar\"]) + \"\\n\"\n",
    "    + \"time l2fm = \" + str(info.times[\"l2fm\"]) + \"\\n\")\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "- Plot gaussian processes if possible to see if there are alive  \n",
    "- Plot accuracies (size of training dataset). Sqsm is exluded since we do not conduct experiments for this criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    print(m.kern)\n",
    "    if info.draw_data:\n",
    "        m.plot(plot_density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rand = np.loadtxt(\"./Results/\" + info.name + \"/accuracies/acc_rand.txt\")\n",
    "acc_mvar = np.loadtxt(\"./Results/\" + info.name + \"/accuracies/acc_mvar.txt\")\n",
    "acc_RKHS = np.loadtxt(\"./Results/\" + info.name + \"/accuracies/acc_RKHS.txt\")\n",
    "acc_Hvar = np.loadtxt(\"./Results/\" + info.name + \"/accuracies/acc_Hvar.txt\")\n",
    "acc_l2fm = np.loadtxt(\"./Results/\" + info.name + \"/accuracies/acc_l2fm.txt\")\n",
    "# acc_sqsm = np.loadtxt(\"./Results/\" + info.name + \"/accuracies/acc_sqsm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Range(start, length, partition):\n",
    "    return range(start, start + length // partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['figure.figsize'] = (16, 10)\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['font.size'] = 25\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# first 1/partition of acc is shown\n",
    "partition = 2\n",
    "\n",
    "plt.plot(Range(info.start_n, len(acc_rand), partition), acc_rand[:len(acc_rand)//partition], label='rand')\n",
    "plt.plot(Range(info.start_n, len(acc_mvar), partition), acc_mvar[:len(acc_mvar)//partition], label='var')\n",
    "# plt.plot(Range(info.start_n, len(acc_sqsm), partition), acc_sqsm[:len(acc_sqsm)//partition], label='L2')\n",
    "plt.plot(Range(info.start_n, len(acc_RKHS), partition), acc_RKHS[:len(acc_RKHS)//partition], label='RKHS')\n",
    "plt.plot(Range(info.start_n, len(acc_Hvar), partition), acc_Hvar[:len(acc_Hvar)//partition], label='Hvar')\n",
    "plt.plot(Range(info.start_n, len(acc_l2fm), partition), acc_l2fm[:len(acc_l2fm)//partition], label='l2fm')\n",
    "\n",
    "# if info.comparsion:\n",
    "#     plt.plot(Range(info.start_n, len(acc_lr), partition), acc_lr[:len(acc_lr)//partition], label='log. regression')\n",
    "#     plt.plot(Range(info.start_n, len(acc_kn), partition), acc_kn[:len(acc_kn)//partition], label='k-nearest')\n",
    "#     plt.plot(Range(info.start_n, len(acc_dt), partition), acc_dt[:len(acc_dt)//partition], label='decision tree')\n",
    "#     plt.plot(Range(info.start_n, len(acc_rf), partition), acc_rf[:len(acc_rf)//partition], label='random forest')\n",
    "\n",
    "plt.title(\"accuracy(n)\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"size of training dataset\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./Results/\" + info.name + \"/accuracyGP\" + str(partition) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
